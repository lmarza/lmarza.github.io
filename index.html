<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Luca Marzari</title> <meta name="author" content="Luca Marzari"> <meta name="description" content="Luca Marzari academic website."> <meta name="keywords" content="Academic website, Formal Verification of DNNs, Safe DRL"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%A4%96&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://lmarza.github.io/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">Home<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Luca</span> Marzari </h1> <p class="desc"></p> </header> <article> <div class="profile float-left"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/me2-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/me2-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/me2-1400.webp"></source> <img src="/assets/img/me2.png" class="img-fluid z-depth-1 rounded" width="auto" height="auto" alt="me2.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="address"> <p>ğŸ“University of Verona</p> <p>Verona, Italy ğŸ‡®ğŸ‡¹</p> </div> </div> <div class="clearfix"> <p>I am a PhD candidate in Computer Science at the University of Verona, advised by <a href="http://profs.sci.univr.it/~farinelli/" rel="external nofollow noopener" target="_blank">Prof. Alessandro Farinelli</a> and <a href="http://profs.scienze.univr.it/~cicalese/" rel="external nofollow noopener" target="_blank">Prof. Ferdinando Cicalese</a>. Recently, Iâ€™ve also been a visiting researcher in the Robotics Institute at Carnegie Mellon University (CMU), under the supervision of <a href="http://www.cs.cmu.edu/~cliu6/" rel="external nofollow noopener" target="_blank">Prof. Changliu Liu</a>.</p> <p>My <strong>research interests</strong> focus on developing efficient and reliable methods for verifying and enhancing the explainability of deep neural networks (DNNs). I have also designed probabilistic verification algorithms with strong theoretical guarantees to bridge the gap between formal verification and safe deep reinforcement learning. The outcomes of my work have led to several publications in top-tier international conferences and journals in Artificial Intelligence and Verification, and to prestigious collaborations with world-leading universities. You can visit the <a href="https://lmarza.github.io/publications/">publications page</a> for more information on my research activity.</p> <p>Outside of work, I am a rock climberğŸ§—ğŸ» and I also love hikingâ›°ï¸ and <a href="https://www.juzaphoto.com/me.php?l=it&amp;p=111136" rel="external nofollow noopener" target="_blank">photography</a>ğŸ“¸.</p> </div> <br> <br> <h2><a href="/news/" style="color: inherit;">News ğŸ“¢</a></h2> <div class="news"> <div class="table-responsive" style="max-height: 20vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row">2025</th> <td> â€ƒ<strong>November</strong> <ul> <li> <em>â€œProbabilistically Tightened Linear Relaxation-based Perturbation Analysis for Neural Network Verificationâ€</em> has been accepted at the Journal of Artificial Intelligence Research (JAIR)! You can find it <a href="https://www.arxiv.org/pdf/2507.05405" rel="external nofollow noopener" target="_blank">here</a>!ğŸš€ </li> <li> <em>â€œOn the Probabilistic Learnability of Compact Neural Network Preimage Boundsâ€</em> has been accepted and selected for an oral presentation at AAAI 2026!ğŸ¤© You can read it <a href="https://arxiv.org/pdf/2511.11656" rel="external nofollow noopener" target="_blank">here</a>! </li> </ul> â€ƒ<strong>October</strong> <ul> <li> <em>â€œVerifying Online Safety Properties for Safe Deep Reinforcement Learningâ€</em> has been accepted in ACM Transactions on Intelligent Systems and Technology! You can find it <a href="https://dl.acm.org/doi/10.1145/3770068" rel="external nofollow noopener" target="_blank">here</a>!</li> </ul> â€ƒ<strong>July</strong> <ul> <li> <em>â€œDesigning Control Barrier Function via Probabilistic Enumeration for Safe Reinforcement Learning Navigationâ€</em> availble <a href="https://arxiv.org/pdf/2504.21643" rel="external nofollow noopener" target="_blank">here</a> has been accepted at IEEE RA-L 2025! ğŸ¤– </li> <li> New preprint <em>â€œFormal Verification of Variational Quantum Circuitsâ€</em> is availble <a href="https://www.arxiv.org/pdf/2507.10635" rel="external nofollow noopener" target="_blank">here</a>! </li> <li> <em>â€œAdvancing Neural Network Verification through Hierarchical Safety Abstract Interpretationâ€</em> availble <a href="https://arxiv.org/pdf/2505.05235" rel="external nofollow noopener" target="_blank">here</a> has been accepted at ECAI 2025! ğŸš€ </li> <li> New preprint <em>â€œProbabilistically Tightened Linear Relaxation-based Perturbation Analysis for Neural Network Verificationâ€</em> is availble <a href="https://www.arxiv.org/pdf/2507.05405" rel="external nofollow noopener" target="_blank">here</a>! </li> </ul> â€ƒ<strong>May</strong> <ul> <li> <a href="https://arxiv.org/pdf/2407.01639" rel="external nofollow noopener" target="_blank">ModelVerification.jl</a> the first Julia cutting-edge toolbox that contains a suite of state-of-the-art methods for verifying DNNs made during my research period abroad at CMU has been accepted at CAV 2025!ğŸ¤© The toolbox is available <a href="https://github.com/intelligent-control-lab/ModelVerification.jl" rel="external nofollow noopener" target="_blank">here</a>. </li> <li> New preprint <em>â€œAdvancing Neural Network Verification through Hierarchical Safety Abstract Interpretationâ€</em> is availble <a href="https://arxiv.org/pdf/2505.05235" rel="external nofollow noopener" target="_blank">here</a>! </li> <li> RobustX made in collaboration with Imperial College people has been accepted at IJCAI 2025!ğŸš€ We propose a novel Python library to generate robust counterfactual explanations! Check out the <a href="https://arxiv.org/pdf/2502.13751" rel="external nofollow noopener" target="_blank">paper</a> and the <a href="https://github.com/RobustCounterfactualX/RobustX" rel="external nofollow noopener" target="_blank">code</a>! </li> <li> Our paper <em>â€œDesigning Control Barrier Function via Probabilistic Enumeration for Safe Reinforcement Learning Navigationâ€</em> is now available in preprint <a href="https://arxiv.org/pdf/2504.21643" rel="external nofollow noopener" target="_blank">here!</a> We propose a hierarchical control framework leveraging neural network verification techniques to design control barrier functions (CBFs) and policy correction mechanisms that ensure safe reinforcement learning navigation policies.ğŸ¤– </li> </ul> â€ƒ<strong>February</strong> <ul> <li> The journal extension of our paper <em>â€œRigorous Probabilistic Guarantees for Robust Counterfactual Explanationsâ€</em> in collaboration with <a href="https://fraleo.github.io" rel="external nofollow noopener" target="_blank">Francesco Leofante</a> of <a href="https://www.imperial.ac.uk/explainable-artificial-intelligence/" rel="external nofollow noopener" target="_blank"> Centre for Explainable AI</a> is out! Read it <a href="https://www.researchgate.net/publication/389435880_Probabilistically_Robust_Counterfactual_Explanations_under_Model_Changes)" rel="external nofollow noopener" target="_blank">here</a>ğŸš€ </li> <li> RobustX is out!ğŸš€ A new Python library to generate robust counterfactual explanations! Check out the <a href="https://arxiv.org/pdf/2502.13751" rel="external nofollow noopener" target="_blank">paper</a> and the <a href="https://github.com/RobustCounterfactualX/RobustX" rel="external nofollow noopener" target="_blank">code</a> made in collaboration with Imperial College people! </li> </ul> â€ƒ<strong>January</strong> <ul> <li> Our proposal on â€œTackling Environmental Sustainability Challenges via Reinforcement Learning and Counterfactual Explanationsâ€ has been accepted for discussion at the AAAI 2025 Bridge on Explainable AI, Energy, and Critical Infrastructure Systems. Looking forward to engaging discussions on Explainable AI for environmental sustainability! </li> <li> Our paper <a href="https://arxiv.org/pdf/2406.08315" rel="external nofollow noopener" target="_blank">Improving Policy Optimization via Îµ-Retrain</a> made during my research period at CMU under the supervision of <a href="https://www.ri.cmu.edu/ri-faculty/changliu-liu/" rel="external nofollow noopener" target="_blank">Prof. Changliu Liu</a>, has been accepted at AAMAS 2025 ğŸ¤© Happy to have collaborated with <a href="https://emarche.github.io" rel="external nofollow noopener" target="_blank">Enrico Marchesini</a> and <a href="https://priyadonti.com" rel="external nofollow noopener" target="_blank">Prof. Priya Donti</a> of the Laboratory for Information &amp; Decision Systems at MIT for this project! </li> </ul> </td> </tr> <tr> <th scope="row">2024</th> <td> â€ƒ<strong>October</strong> <ul> <li>ECAI 2024 was a blast!ğŸš€ I made an oral presentation on <em>â€œRigorous Probabilistic Guarantees for Robust Counterfactual Explanationsâ€</em> and an outreach activity with Francesco. We showed how model changes can invalidate counterfactuals and pose challenges when these explanations are used to provide recourse recommendations! In case you missed it, check out my GitHub page; Iâ€™ll post the demo used during the outreach soon!</li> </ul> â€ƒ<strong>July</strong> <ul> <li>Our paper <em>â€œRigorous Probabilistic Guarantees for Robust Counterfactual Explanationsâ€</em> in collaboration with <a href="https://fraleo.github.io" rel="external nofollow noopener" target="_blank">Francesco Leofante</a> of <a href="https://www.imperial.ac.uk/explainable-artificial-intelligence/" rel="external nofollow noopener" target="_blank"> Centre for Explainable AI </a> at Imperial College has been accepted at the 27th <a href="https://www.ecai2024.eu" rel="external nofollow noopener" target="_blank"> European Conference on Artificial Intelligence</a> (ECAI 2024) ğŸ‰. See you in Santiago de Compostela!</li> </ul> â€ƒ<strong>June</strong> <ul> <li>Two new papers produced during the research period at CMU are now available in pre-print! <ul> <li> <a href="https://arxiv.org/pdf/2406.08315" rel="external nofollow noopener" target="_blank">Improving Policy Optimization via Îµ-Retrain</a>. Happy to have collaborated with <a href="https://emarche.github.io" rel="external nofollow noopener" target="_blank">Enrico Marchesini</a> and <a href="https://priyadonti.com" rel="external nofollow noopener" target="_blank">Prof. Priya Donti</a> of the Laboratory for Information &amp; Decision Systems at MIT for this project! </li> <li> <a href="https://arxiv.org/pdf/2407.01639" rel="external nofollow noopener" target="_blank">ModelVerification.jl</a>: the first Julia cutting-edge toolbox that contains a suite of state-of-the-art methods for verifying DNNs. </li> </ul> </li> </ul> â€ƒ<strong>January</strong> <ul> <li>Our paper <em>â€œEnumerating Safe Regions in Deep Neural Networks with Provable Probabilistic Guaranteesâ€</em> has been selected for an oral presentation at <a href="https://aaai.org/aaai-conference/" rel="external nofollow noopener" target="_blank">AAAI</a> 2024 ğŸ¤©.</li> </ul> </td> </tr> <tr> <th scope="row">2023</th> <td> â€ƒ<strong>Dec</strong> <ul> <li>New paper accepted at <a href="https://aaai.org/aaai-conference/" rel="external nofollow noopener" target="_blank">AAAI</a> 2024: <em>â€œEnumerating Safe Regions in Deep Neural Networks with Provable Probabilistic Guaranteesâ€</em>.</li> </ul> â€ƒ<strong>Nov</strong> <ul> <li> <em>â€œScaling #DNN-Verification Tools with Efficient Bound Propagation and Parallel Computingâ€</em> has been accepted at the 10th Italian Workshop on Artificial Intelligence and Robotics <a href="https://www.airo-aixia.it/airo2023/" rel="external nofollow noopener" target="_blank">(AIRO 2023)</a> , co-located with the 22nd International Conference of the Italian Association for Artificial Intelligence (AI*IA 2023).</li> </ul> â€ƒ<strong>Jun</strong> <ul> <li> Our paper <em>â€œFormal Verification for Counting Unsafe Inputs in Deep Neural Networksâ€</em> has been accepted at the 2nd Workshop on Formal Verification of Machine Learning <a href="https://www.ml-verification.com" rel="external nofollow noopener" target="_blank">(WFVML 2023)</a> at ICML 2023! </li> <li> Our paper <em>â€œConstrained Reinforcement Learning and Formal Verification for Safe Colonoscopy Navigationâ€</em> has been accepted at <a href="https://ieee-iros.org" rel="external nofollow noopener" target="_blank">IROS 2023!</a> ğŸ¤– </li> </ul> â€ƒ<strong>May</strong> <ul> <li>Excited to share that in July Iâ€™ll start a research visit at the <a href="http://icontrol.ri.cmu.edu" rel="external nofollow noopener" target="_blank">Intelligent Controll Lab</a> part of the Robotics Institute at Carnegie Mellon University(CMU) ğŸ‡ºğŸ‡¸, under the supervision of <a href="http://www.cs.cmu.edu/~cliu6/" rel="external nofollow noopener" target="_blank">Prof. Changliu Liu</a>.</li> </ul> â€ƒ<strong>April</strong> <ul> <li>Our paper <em>â€œThe #DNN-Verification Problem: Counting Unsafe Inputs for Deep Neural Networksâ€</em> has been accepted at <a href="https://ijcai-23.org/" rel="external nofollow noopener" target="_blank">IJCAI 2023</a> (15% acceptance rate) ğŸ¤©.</li> </ul> â€ƒ<strong>January</strong> <ul> <li> Our paper <em>â€œVerifying Learning-Based Robotic Navigation Systemsâ€</em> in collaboration with <a href="https://www.katz-lab.com/" rel="external nofollow noopener" target="_blank">The Katz Lab</a> has been accepted at <a href="https://www.etaps.org/2023/conferences/" rel="external nofollow noopener" target="_blank"> ETAPS TACAS 2023</a> ğŸš€. </li> <li> Our paper <em>â€œOnline Safety Property Collection and Refinement for Safe Deep Reinforcement Learning in Mapless Navigationâ€</em> has been accepted at <a href="https://www.icra2023.org" rel="external nofollow noopener" target="_blank">ICRA 2023</a>. </li> <li> Our paper <em>â€œSafe Deep Reinforcement Learning by Verifying Task-Level Propertiesâ€</em> has been accepted at <a href="https://aamas2023.soton.ac.uk" rel="external nofollow noopener" target="_blank">AAMAS 2023</a>. </li> </ul> </td> </tr> <tr> <th scope="row">2022</th> <td> â€ƒ<strong>October</strong> <ul> <li>Excited to start a PhD in Computer Science advised by Prof. Alessandro Farinelli and Prof. Ferdinando Cicalese at the Department of Computer Science, Verona.</li> </ul> â€ƒ<strong>April</strong> <ul> <li>I Started a Research Fellowship under the supervision of Prof. Alessandro Farinelli at the Department of Computer Science, Verona.</li> </ul> </td> </tr> <tr> <th scope="row">2021</th> <td> â€ƒ<strong>December</strong> <ul> <li>1 poster paper accepted at <a href="https://sac2022-irmas.isr.uc.pt/" rel="external nofollow noopener" target="_blank">ACM SAC IRMAS</a> (&lt; 25% acceptance rate) on <em>â€œCurriculum Learning For Safe Mapless Navigationâ€</em>.</li> </ul> â€ƒ<strong>September</strong> <ul> <li>1 paper accepted at <a href="https://www.ieee-ras.org/conferences-workshops/technically-co-sponsored/icar" rel="external nofollow noopener" target="_blank">IEEE ICAR</a> on <em>â€œTowards Hierarchical Task Decomposition using Deep Reinforcement Learning for Pick and Place Subtasksâ€</em>.</li> </ul> </td> </tr> </table> </div> </div> <br> <br> <h2><a href="/publications/" style="color: inherit;">Selected publications ğŸ“š</a></h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">AAAI</abbr></div> <div id="marzari2026rfprove" class="col-sm-8"> <div class="title">On the Probabilistic Learnability of Compact Neural Network Preimage Bounds</div> <div class="author"> <em>Luca Marzari</em>,Â Manuele Bicego,Â Ferdinando Cicalese,Â andÂ Alessandro Farinelli</div> <div class="periodical"> <em>Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)</em>, 2026 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2511.11656" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://arxiv.org/pdf/2511.11656" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/lmarza/ProbVerNet/tree/AAAI26" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Although recent provable methods have been developed to compute preimage bounds for neural networks, their scalability is fundamentally limited by the #P-hardness of the problem. In this work, we adopt a novel probabilistic perspective, aiming to deliver solutions with high-confidence guarantees and bounded error. To this end, we investigate the potential of bootstrap-based and randomized approaches that are capable of capturing complex patterns in high-dimensional spaces, including input regions where a given output property holds. In detail, we introduce *R*andom *F*orest *Pro*perty *Ve*rifier (RF-ProVe), a method that exploits an ensemble of randomized decision trees to generate candidate input regions satisfying a desired output property and refines them through active resampling. Our theoretical derivations offer formal statistical guarantees on region purity and global coverage, providing a practical, scalable solution for computing compact preimage approximations in cases where exact solvers fail to scale.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">JAIR</abbr></div> <div id="marzari2025PTlirpa" class="col-sm-8"> <div class="title">Probabilistically Tightened Linear Relaxation-based Perturbation Analysis for Neural Network Verification</div> <div class="author"> <em>Luca Marzari</em>,Â Ferdinando Cicalese,Â andÂ Alessandro Farinelli</div> <div class="periodical"> <em>Journal of Artificial Intelligence Research (JAIR)</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://www.arxiv.org/abs/2507.05405" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://www.arxiv.org/pdf/2507.05405" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/lmarza/ProbVerNet" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>We present *P*robabilistically *T*ightened *Li*near *R*elaxation-based *P*erturbation *A*nalysis (PT-LiRPA), a novel framework that combines over-approximation techniques from LiRPA-based approaches with a sampling-based method to compute tight intermediate reachable sets. In detail, we show that with negligible computational overhead, PT-LiRPA exploiting the estimated reachable sets, significantly tightens the lower and upper linear bounds of a neural networkâ€™s output, reducing the computational cost of formal verification tools while providing probabilistic guarantees on verification soundness. Extensive experiments on standard formal verification benchmarks, including the International Verification of Neural Networks Competition, show that our PT-LiRPA-based verifier improves robustness certificates by up to 3.31X and 2.26X compared to related work. Importantly, our probabilistic approach results in a valuable solution for challenging competition entries where state-of-the-art formal verification methods fail, allowing us to provide answers with high confidence (i.e., at least 99%).</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">ECAI</abbr></div> <div id="marzari2024Rigorous" class="col-sm-8"> <div class="title">Rigorous Probabilistic Guarantees for Robust Counterfactual Explanations</div> <div class="author"> <em>Luca Marzari</em>,Â Francesco Leofante,Â Ferdinando Cicalese,Â andÂ Alessandro Farinelli</div> <div class="periodical"> <em>Proceedings of the 27th European Conference on Artificial Intelligence (ECAI)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2407.07482" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://arxiv.org/pdf/2407.07482" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/lmarza/APAS" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>We study the problem of assessing the robustness of counterfactual explanations for deep learning models. We focus on plausible model shifts altering model parameters and propose a novel framework to reason about the robustness property in this setting. To motivate our solution, we begin by showing for the first time that computing the robustness of counterfactuals with respect to plausible model shifts is NP-complete. As this (practically) rules out the existence of scalable algorithms for exactly computing robustness, we propose a novel probabilistic approach which is able to provide tight estimates of robustness with strong guarantees while preserving scalability. Remarkably, and differently from existing solutions targeting plausible model shifts, our approach does not impose requirements on the network to be analyzed, thus enabling robustness analysis on a wider range of architectures. Experiments on four binary classification datasets indicate that our method improves the state of the art in generating robust explanations, outperforming existing methods on a range of metrics.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">AAAI</abbr></div> <div id="marzari2023enumeration" class="col-sm-8"> <div class="title">Enumerating Safe Regions in Deep Neural Networks with Provable Probabilistic Guarantees</div> <div class="author"> <em>Luca Marzari</em>,Â Davide Corsi,Â Enrico Marchesini,Â Alessandro Farinelli,Â andÂ Ferdinando Cicalese</div> <div class="periodical"> <em>Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2308.09842" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://arxiv.org/pdf/2308.09842.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/lmarza/ProbVerNet/tree/AAAI24" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Identifying safe areas is a key point to guarantee trust for systems that are based on Deep Neural Networks (DNNs). To this end, we introduce the AllDNN-Verification problem: given a safety property and a DNN, enumerate the set of all the regions of the property input domain which are safe, i.e., where the property does hold. Due to the #P-hardness of the problem, we propose an efficient approximation method called Îµ-ProVe. Our approach exploits a controllable underestimation of the output reachable sets obtained via statistical prediction of tolerance limits, and can provide a tight (with provable probabilistic guarantees) lower estimate of the safe areas. Our empirical evaluation on different standard benchmarks shows the scalability and effectiveness of our method, offering valuable insights for this new type of verification of DNNs.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">IJCAI</abbr></div> <div id="marzari2023dno" class="col-sm-8"> <div class="title">The #DNN-Verification Problem: Counting Unsafe Inputs for Deep Neural Networks</div> <div class="author"> <em>Luca Marzari</em>,Â Davide Corsi,Â Ferdinando Cicalese,Â andÂ Alessandro Farinelli</div> <div class="periodical"> <em>Internation Joint Conference on Artificial Intelligence (IJCAI)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2301.07068" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://arxiv.org/pdf/2301.07068.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/lmarza/ProbVerNet" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Deep Neural Networks are increasingly adopted in critical tasks that require a high level of safety, e.g., autonomous driving. While state-of-the-art verifiers can be employed to check whether a DNN is unsafe w.r.t. some given property (i.e., whether there is at least one unsafe input configuration), their yes/no output is not informative enough for other purposes, such as shielding, model selection, or training improvements. In this paper, we introduce the #DNN-Verification problem, which involves counting the number of input configurations of a DNN that result in a violation of a particular safety property. We analyze the complexity of this problem and propose a novel approach that returns the exact count of violations. Due to the #P-completeness of the problem, we also propose a randomized, approximate method that provides a provable probabilistic bound of the correct count while significantly reducing computational requirements. We present experimental results on a set of safety-critical benchmarks that demonstrate the effectiveness of our approximate method and evaluate the tightness of the bound.</p> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%6C%75%63%61.%6D%61%72%7A%61%72%69@%75%6E%69%76%72.%69%74" title="email"><i class="fas fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=iGdATZsAAAAJ&amp;hl" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://www.semanticscholar.org/author/2047998201" title="Semantic Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-semantic-scholar"></i></a> <a href="https://github.com/lmarza" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fab fa-github"></i></a> <a href="https://www.linkedin.com/in/luca-marzari-922874170" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fab fa-linkedin"></i></a> <a href="https://twitter.com/lmarza_" title="Twitter" rel="external nofollow noopener" target="_blank"><i class="fab fa-twitter"></i></a> </div> <div class="contact-note"> Feel free to send an email about Formal Verification of DNN! </div> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> Â© Copyright 2025 Luca Marzari. Last updated: November 25, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://unpkg.com/bootstrap-table@/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js"></script> <script defer src="/assets/js/common.js"></script> <script defer src="/assets/js/copy_code.js" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>